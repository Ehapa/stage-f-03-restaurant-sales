{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/home/jovyan/20-restaurant-sales/data/out\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to retrieve data from kaggle for the train component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(download_url, out_path):\n",
    "    import subprocess\n",
    "    import pickle\n",
    "    import sys\n",
    "    import subprocess\n",
    "    \n",
    "    \n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'pandas'])\n",
    "    \n",
    "    import pandas as pd\n",
    "    \n",
    "    \n",
    "    default_url = \"https://storage.googleapis.com/my-mldata/restaurant-revenue-prediction.zip\"\n",
    "    url = download_url if download_url else default_url\n",
    "    \n",
    "    subprocess.run([\"wget\", \"-O\", \"restaurant-revenue-prediction.zip\", url])\n",
    "    \n",
    "    subprocess.run([\"unzip\", \"restaurant-revenue-prediction.zip\"])\n",
    "    subprocess.run([\"unzip\", \"*.zip\"])\n",
    "    print(\"Files Unzipped....\")\n",
    "    subprocess.call([\"rm\", \"-r\", \"*.zip\"])\n",
    "    \n",
    "    train_data = pd.read_csv(\"train.csv\")\n",
    "    test_data = pd.read_csv(\"test.csv\")\n",
    "    \n",
    "    with open(f\"{out_path}/train_data.pkl\", \"wb\") as train:\n",
    "        pickle.dump(train_data, train)\n",
    "        \n",
    "    with open(f\"{out_path}/test_data.pkl\", \"wb\") as test:\n",
    "        pickle.dump(test_data, test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files Unzipped....\n"
     ]
    }
   ],
   "source": [
    "get_data(\"\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to preprocess the data using correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_corr_analysis(out_path):\n",
    "    \n",
    "    import sys\n",
    "    import subprocess\n",
    "    \n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'pandas', 'scikit-learn'])\n",
    "#     subprocess.run([sys.executable, '-m', 'pip', 'install', 'scikit-learn'])\n",
    "    \n",
    "    import pickle\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import pandas as pd\n",
    "    \n",
    "    with open(f\"{out_path}/train_data.pkl\", 'rb') as f:\n",
    "        train = pickle.load(f)\n",
    "        \n",
    "    with open(f\"{out_path}/test_data.pkl\", 'rb') as f:\n",
    "        test = pickle.load(f) \n",
    "       \n",
    "    train.drop(['Id', 'Open Date', 'City'], axis=1, inplace=True)\n",
    "    test.drop(['Id', 'Open Date', 'City'], axis=1, inplace=True)\n",
    "    \n",
    "    city_group_encoder = LabelEncoder()\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    train['City Group'] = city_group_encoder.fit_transform(train['City Group'])\n",
    "    test['City Group'] = city_group_encoder.transform(test['City Group'])\n",
    "\n",
    "    train = pd.get_dummies(train, drop_first=True)\n",
    "    test = pd.get_dummies(test, drop_first=True)\n",
    "\n",
    "    X = train.drop(['revenue'], axis=1)\n",
    "    y = train[['revenue']]\n",
    "\n",
    "    test.drop([\"Type_MB\"], axis=1, inplace=True)\n",
    "    \n",
    "    corr_matrix = X.corr().abs()\n",
    "    \n",
    "    condition = np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool)\n",
    "    upper = corr_matrix.where(condition)\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "    \n",
    "    X.drop(to_drop, axis=1, inplace=True)\n",
    "    test.drop(to_drop, axis=1, inplace=True)\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15)\n",
    "\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "    X_val = scaler.transform(X_val)\n",
    "\n",
    "    test = scaler.transform(test)\n",
    "    \n",
    "#     outfile = TemporaryFile()\n",
    "    np.savez_compressed(f'{out_path}/corr-analysis-data.npz',\n",
    "                       X_train=X_train,\n",
    "                       X_val=X_val,\n",
    "                       y_train=y_train,\n",
    "                       y_val=y_val,\n",
    "                       test_data=test)\n",
    "    print(\"Preprocessing Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess_corr_analysis(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pca_analysis(out_path):\n",
    "    \n",
    "    import sys\n",
    "    import subprocess\n",
    "    \n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'pandas', 'scikit-learn'])\n",
    "\n",
    "      \n",
    "    import pickle\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.decomposition import PCA\n",
    "    import pandas as pd\n",
    "    \n",
    "    with open(f\"{out_path}/train_data.pkl\", 'rb') as f:\n",
    "        train = pickle.load(f)\n",
    "        \n",
    "    with open(f\"{out_path}/test_data.pkl\", 'rb') as f:\n",
    "        test = pickle.load(f) \n",
    "       \n",
    "    train.drop(['Id', 'Open Date', 'City'], axis=1, inplace=True)\n",
    "    test.drop(['Id', 'Open Date', 'City'], axis=1, inplace=True)\n",
    "    \n",
    "    city_group_encoder = LabelEncoder()\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    train['City Group'] = city_group_encoder.fit_transform(train['City Group'])\n",
    "    test['City Group'] = city_group_encoder.transform(test['City Group'])\n",
    "\n",
    "    train = pd.get_dummies(train, drop_first=True)\n",
    "    test = pd.get_dummies(test, drop_first=True)\n",
    "\n",
    "    X = train.drop(['revenue'], axis=1)\n",
    "    y = train[['revenue']]\n",
    "\n",
    "    test.drop([\"Type_MB\"], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15)\n",
    "\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "    X_val = scaler.transform(X_val)\n",
    "\n",
    "    test = scaler.transform(test)\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    \n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    \n",
    "    X_val = pca.transform(X_val)\n",
    "\n",
    "    test = pca.transform(test)\n",
    "    \n",
    "    print(test[:3, :])\n",
    "#     outfile = TemporaryFile()\n",
    "    np.savez_compressed(f'{out_path}/pca-analysis-data.npz',\n",
    "                       X_train=X_train,\n",
    "                       X_val=X_val,\n",
    "                       y_train=y_train,\n",
    "                       y_val=y_val,\n",
    "                       test_data=test)\n",
    "    print(\"Preprocessing Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to train the data with Linear Regression Model with Ridge regularization - train component (train-ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_corr_ridge(out_path, ridge_corr_file):\n",
    "    \n",
    "    import sys\n",
    "    import subprocess\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'pandas', 'scikit-learn'])\n",
    "    from sklearn.linear_model import Ridge\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    \n",
    "    preprocessed_data = np.load(f'{out_path}/corr-analysis-data.npz')\n",
    "    X_train = preprocessed_data['X_train']\n",
    "    y_train = preprocessed_data['y_train']\n",
    "    \n",
    "    X_val = preprocessed_data['X_val']\n",
    "    y_val = preprocessed_data['y_val']\n",
    "    ridge = Ridge(alpha=0.1)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = ridge.predict(X_val)\n",
    "    \n",
    "    with open(f'{out_path}/{ridge_corr_file}', \"wb\") as model:\n",
    "        pickle.dump(ridge, model)\n",
    "    \n",
    "    RMSE = np.sqrt(mean_squared_error(y_pred, y_val))\n",
    "    \n",
    "    print(f\"RMSE: {RMSE}\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_corr_ridge(output_dir, 'ridge-corr-model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pca_ridge(out_path, ridge_pca_file):\n",
    "    \n",
    "    import sys\n",
    "    import subprocess\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'pandas', 'scikit-learn'])\n",
    "    from sklearn.linear_model import Ridge\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    \n",
    "    preprocessed_data = np.load(f'{out_path}/pca-analysis-data.npz')\n",
    "    X_train = preprocessed_data['X_train']\n",
    "    y_train = preprocessed_data['y_train']\n",
    "    \n",
    "    X_val = preprocessed_data['X_val']\n",
    "    y_val = preprocessed_data['y_val']\n",
    "    ridge = Ridge(alpha=0.1)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = ridge.predict(X_val)\n",
    "    \n",
    "    with open(f'{out_path}/{ridge_pca_file}', \"wb\") as model:\n",
    "        pickle.dump(ridge, model)\n",
    "    \n",
    "    RMSE = np.sqrt(mean_squared_error(y_pred, y_val))\n",
    "    \n",
    "    print(f\"RMSE: {RMSE}\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to train the data with Linear Regression Model with Lasso regularization - train component (train-lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_corr_lasso(out_path, lasso_corr_file):\n",
    "    \n",
    "    import sys\n",
    "    import subprocess\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'pandas', 'scikit-learn'])\n",
    "    from sklearn.linear_model import Lasso\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    \n",
    "    preprocessed_data = np.load(f'{out_path}/corr-analysis-data.npz')\n",
    "    X_train = preprocessed_data['X_train']\n",
    "    y_train = preprocessed_data['y_train']\n",
    "    \n",
    "    X_val = preprocessed_data['X_val']\n",
    "    y_val = preprocessed_data['y_val']\n",
    "    lasso = Lasso(alpha=0.1)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = lasso.predict(X_val)\n",
    "    \n",
    "    with open(f'{out_path}/{lasso_corr_file}', \"wb\") as model:\n",
    "        pickle.dump(lasso, model)\n",
    "    \n",
    "    RMSE = np.sqrt(mean_squared_error(y_pred, y_val))\n",
    "    \n",
    "    print(f\"RMSE(Lasso) - Corr: {RMSE}\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pca_lasso(out_path, lasso_pca_file):\n",
    "    \n",
    "    import sys\n",
    "    import subprocess\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'pandas', 'scikit-learn'])\n",
    "    from sklearn.linear_model import Lasso\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    \n",
    "    preprocessed_data = np.load(f'{out_path}/pca-analysis-data.npz')\n",
    "    X_train = preprocessed_data['X_train']\n",
    "    y_train = preprocessed_data['y_train']\n",
    "    \n",
    "    X_val = preprocessed_data['X_val']\n",
    "    y_val = preprocessed_data['y_val']\n",
    "    lasso = Lasso(alpha=0.1)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = lasso.predict(X_val)\n",
    "    \n",
    "    with open(f'{out_path}/{lasso_pca_file}', \"wb\") as model:\n",
    "        pickle.dump(lasso, model)\n",
    "    \n",
    "    RMSE = np.sqrt(mean_squared_error(y_pred, y_val))\n",
    "    print(X_train[:5, :])\n",
    "    print(f\"RMSE(Lasso|PCA): {RMSE}\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_corr_xgb(out_path, xgb_corr_file):\n",
    "    \n",
    "    import sys\n",
    "    import subprocess\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'pandas', 'scikit-learn', 'xgboost'])\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    import xgboost as xgb\n",
    "    \n",
    "    preprocessed_data = np.load(f'{out_path}/corr-analysis-data.npz')\n",
    "    X_train = preprocessed_data['X_train']\n",
    "    y_train = preprocessed_data['y_train']\n",
    "    X_val = preprocessed_data['X_val']\n",
    "    y_val = preprocessed_data['y_val']\n",
    "    \n",
    "    xg_reg = xgb.XGBRegressor(objective='reg:linear', colsample_bytree=0.3,\n",
    "                              learning_rate=0.1, max_depth=5, alpha=10, n_estimators=10)\n",
    "\n",
    "    xg_reg.fit(X_train, y=y_train)\n",
    "    \n",
    "    y_pred = xg_reg.predict(X_val)\n",
    "    \n",
    "    with open(f'{out_path}/{xgb_corr_file}', \"wb\") as model:\n",
    "        pickle.dump(xg_reg, model)\n",
    "    \n",
    "    RMSE = np.sqrt(mean_squared_error(y_pred, y_val))\n",
    "    \n",
    "    print(f\"RMSE(XGBoost): {RMSE}\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pca_xgb(out_path, xgb_pca_file):\n",
    "    \n",
    "    import sys\n",
    "    import subprocess\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'pandas', 'scikit-learn', 'xgboost'])\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    import xgboost as xgb\n",
    "    \n",
    "    preprocessed_data = np.load(f'{out_path}/pca-analysis-data.npz')\n",
    "    X_train = preprocessed_data['X_train']\n",
    "    y_train = preprocessed_data['y_train']\n",
    "    X_val = preprocessed_data['X_val']\n",
    "    y_val = preprocessed_data['y_val']\n",
    "    \n",
    "    xg_reg = xgb.XGBRegressor(objective='reg:linear', colsample_bytree=0.3,\n",
    "                              learning_rate=0.1, max_depth=5, alpha=10, n_estimators=10)\n",
    "\n",
    "    xg_reg.fit(X_train, y=y_train)\n",
    "    \n",
    "    y_pred = xg_reg.predict(X_val)\n",
    "    \n",
    "    with open(f'{out_path}/{xgb_pca_file}', \"wb\") as model:\n",
    "        pickle.dump(xg_reg, model)\n",
    "    \n",
    "    print(X_train[:3, :])\n",
    "    RMSE = np.sqrt(mean_squared_error(y_pred, y_val))\n",
    "    \n",
    "    print(f\"RMSE(XGBoost)| PCA: {RMSE}\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to predict with Linear Regression Model with Ridge regularization - train component (predict-ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_corr_ridge(out_path, ridge_corr_file):\n",
    "    \n",
    "    import pickle\n",
    "    import sys\n",
    "    import subprocess\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'pandas', 'scikit-learn'])\n",
    "    import numpy as np\n",
    "    \n",
    "    with open(f'{out_path}/{ridge_corr_file}', \"rb\") as model:\n",
    "        ridge = pickle.load(model)\n",
    "        \n",
    "    test_data = np.load(f'{out_path}/corr-analysis-data.npz')['test_data']\n",
    "    \n",
    "    predictions = ridge.predict(test_data)\n",
    "    \n",
    "    np.savetxt(f'{out_path}/ridge-corr.txt', predictions, fmt='%1.2f')\n",
    "    \n",
    "#     sample_submission = pd.read_csv()\n",
    "    print(\"File saved as ridge-corr.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_pca_ridge(out_path, ridge_pca_file):\n",
    "    \n",
    "    import pickle\n",
    "    import sys\n",
    "    import subprocess\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'pandas', 'scikit-learn'])\n",
    "    import numpy as np\n",
    "    \n",
    "    with open(f'{out_path}/{ridge_pca_file}', \"rb\") as model:\n",
    "        ridge = pickle.load(model)\n",
    "        \n",
    "    test_data = np.load(f'{out_path}/pca-analysis-data.npz')['test_data']\n",
    "    \n",
    "    predictions = ridge.predict(test_data)\n",
    "    \n",
    "    np.savetxt(f'{out_path}/ridge-pca.txt', predictions, fmt='%1.2f')\n",
    "    \n",
    "#     sample_submission = pd.read_csv()\n",
    "    print(\"File saved as ridge-pca.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_corr_lasso(out_path, lasso_corr_file):\n",
    "    \n",
    "    import pickle\n",
    "    import sys\n",
    "    import subprocess\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'pandas', 'scikit-learn'])\n",
    "    import numpy as np\n",
    "    \n",
    "    with open(f'{out_path}/{lasso_corr_file}', \"rb\") as model:\n",
    "        lasso = pickle.load(model)\n",
    "        \n",
    "    test_data = np.load(f'{out_path}/corr-analysis-data.npz')['test_data']\n",
    "    \n",
    "    predictions = lasso.predict(test_data)\n",
    "    \n",
    "    np.savetxt(f'{out_path}/lasso-corr.txt', predictions, fmt='%1.2f')\n",
    "    \n",
    "#     sample_submission = pd.read_csv()\n",
    "    print(\"File saved as lasso-corr.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_pca_lasso(out_path, lasso_pca_file):\n",
    "    \n",
    "    import pickle\n",
    "    import sys\n",
    "    import subprocess\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'pandas', 'scikit-learn'])\n",
    "    import numpy as np\n",
    "    \n",
    "    with open(f'{out_path}/{lasso_pca_file}', \"rb\") as model:\n",
    "        lasso = pickle.load(model)\n",
    "        \n",
    "    test_data = np.load(f'{out_path}/pca-analysis-data.npz')['test_data']\n",
    "    print(\"==========================================================================================================\\n\")\n",
    "    print(test_data[:3, :])\n",
    "    print(\"==========================================================================================================\\n\")\n",
    "    predictions = lasso.predict(test_data)\n",
    "    \n",
    "    np.savetxt(f'{out_path}/lasso-pca.txt', predictions, fmt='%1.2f')\n",
    "    \n",
    "#     sample_submission = pd.read_csv()\n",
    "    print(\"File saved as lasso-pca.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_corr_xgb(out_path, xgb_corr_file):\n",
    "    \n",
    "    import pickle\n",
    "    import sys\n",
    "    import subprocess\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'pandas', 'scikit-learn', 'xgboost'])\n",
    "    import numpy as np\n",
    "    import xgboost\n",
    "    \n",
    "    with open(f'{out_path}/{xgb_corr_file}', \"rb\") as model:\n",
    "        xgb = pickle.load(model)\n",
    "        \n",
    "    test_data = np.load(f'{out_path}/corr-analysis-data.npz')['test_data']\n",
    "    \n",
    "    predictions = xgb.predict(test_data)\n",
    "    \n",
    "    np.savetxt(f'{out_path}/xgb-corr.txt', predictions, fmt='%1.2f')\n",
    "    \n",
    "    print(\"File saved as xgb-corr.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_pca_xgb(out_path, xgb_pca_file):\n",
    "    \n",
    "    import pickle\n",
    "    import sys\n",
    "    import subprocess\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'pandas', 'scikit-learn', 'xgboost'])\n",
    "    import numpy as np\n",
    "    import xgboost\n",
    "    \n",
    "    with open(f'{out_path}/{xgb_pca_file}', \"rb\") as model:\n",
    "        xgb = pickle.load(model)\n",
    "        \n",
    "    test_data = np.load(f'{out_path}/pca-analysis-data.npz')['test_data']\n",
    "    print(test_data[:3, :])\n",
    "    predictions = xgb.predict(test_data)\n",
    "    \n",
    "    np.savetxt(f'{out_path}/xgb-pca.txt', predictions, fmt='%1.2f')\n",
    "    \n",
    "    print(\"File saved as xgb-pca.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_ridge(output_dir, 'corr-ridge-model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to predict with Linear Regression Model with Ridge regularization - train component (predict-ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import dsl\n",
    "import kfp.components as comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_op = comp.func_to_container_op(get_data, base_image=\"python:3.7\")\n",
    "\n",
    "preprocess_corr_op = comp.func_to_container_op(preprocess_corr_analysis, base_image=\"tensorflow/tensorflow:latest-gpu-py3\")\n",
    "preprocess_pca_op = comp.func_to_container_op(preprocess_pca_analysis, base_image=\"tensorflow/tensorflow:latest-gpu-py3\")\n",
    "\n",
    "train_corr_ridge_op = comp.func_to_container_op(train_corr_ridge, base_image=\"tensorflow/tensorflow:latest-gpu-py3\")\n",
    "train_corr_lasso_op = comp.func_to_container_op(train_corr_lasso, base_image=\"tensorflow/tensorflow:latest-gpu-py3\")\n",
    "train_corr_xgb_op = comp.func_to_container_op(train_corr_xgb, base_image=\"tensorflow/tensorflow:latest-gpu-py3\")\n",
    "\n",
    "predict_corr_ridge_op = comp.func_to_container_op(predict_corr_ridge, base_image=\"tensorflow/tensorflow:latest-gpu-py3\")\n",
    "predict_corr_lasso_op = comp.func_to_container_op(predict_corr_lasso, base_image=\"tensorflow/tensorflow:latest-gpu-py3\")\n",
    "predict_corr_xgb_op = comp.func_to_container_op(predict_corr_xgb, base_image=\"tensorflow/tensorflow:latest-gpu-py3\")\n",
    "\n",
    "train_pca_ridge_op = comp.func_to_container_op(train_pca_ridge, base_image=\"tensorflow/tensorflow:latest-gpu-py3\")\n",
    "train_pca_lasso_op = comp.func_to_container_op(train_pca_lasso, base_image=\"tensorflow/tensorflow:latest-gpu-py3\")\n",
    "train_pca_xgb_op = comp.func_to_container_op(train_pca_xgb, base_image=\"tensorflow/tensorflow:latest-gpu-py3\")\n",
    "\n",
    "predict_pca_ridge_op = comp.func_to_container_op(predict_pca_ridge, base_image=\"tensorflow/tensorflow:latest-gpu-py3\")\n",
    "predict_pca_lasso_op = comp.func_to_container_op(predict_pca_lasso, base_image=\"tensorflow/tensorflow:latest-gpu-py3\")\n",
    "predict_pca_xgb_op = comp.func_to_container_op(predict_pca_xgb, base_image=\"tensorflow/tensorflow:latest-gpu-py3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=\"Restaurant Sales Revenue Prediction\",\n",
    "    description=\"A Machine Learning Pipeline for Revenue prediction model\"\n",
    ")\n",
    "\n",
    "def revenue_prediction_pipeline(\n",
    "    out_path: str,\n",
    "    ridge_corr_file: str,\n",
    "    lasso_corr_file: str,\n",
    "    xgb_corr_file: str,\n",
    "    ridge_pca_file: str,\n",
    "    lasso_pca_file: str,\n",
    "    xgb_pca_file: str,\n",
    "    download_url: str\n",
    "):\n",
    "    volume_op = dsl.VolumeOp(\n",
    "        name=\"create_volume\",\n",
    "        resource_name=\"data-volume\",\n",
    "        size=\"1Gi\",\n",
    "        modes=dsl.VOLUME_MODE_RWO)\n",
    "    \n",
    "    download_container = download_op(download_url, out_path).add_pvolumes({out_path: volume_op.volume})\n",
    "    \n",
    "    preprocess_corr_container = preprocess_corr_op(out_path).add_pvolumes({out_path: download_container.pvolume})\n",
    "    \n",
    "    train_ridge_corr_container = train_corr_ridge_op(out_path, ridge_corr_file) \\\n",
    "                                        .add_pvolumes({out_path: preprocess_corr_container.pvolume})\n",
    "    \n",
    "    train_lasso_corr_container = train_corr_lasso_op(out_path, lasso_corr_file) \\\n",
    "                                        .add_pvolumes({out_path: preprocess_corr_container.pvolume})\n",
    "    \n",
    "    train_xgb_corr_container = train_corr_xgb_op(out_path, xgb_corr_file) \\\n",
    "                                        .add_pvolumes({out_path: preprocess_corr_container.pvolume})\n",
    "    \n",
    "    predict_ridge_corr_container = predict_corr_ridge_op(out_path, ridge_corr_file) \\\n",
    "                                        .add_pvolumes({out_path: train_ridge_corr_container.pvolume})\n",
    "    \n",
    "    predict_lasso_corr_container = predict_corr_lasso_op(out_path, lasso_corr_file) \\\n",
    "                                        .add_pvolumes({out_path: train_lasso_corr_container.pvolume})\n",
    "    \n",
    "    predict_xgb_corr_container = predict_corr_xgb_op(out_path, xgb_corr_file) \\\n",
    "                                        .add_pvolumes({out_path: train_xgb_corr_container.pvolume})\n",
    "    \n",
    "    \n",
    "    #PCA\n",
    "    preprocess_pca_container = preprocess_pca_op(out_path).add_pvolumes({out_path: download_container.pvolume})\n",
    "    \n",
    "    train_ridge_pca_container = train_pca_ridge_op(out_path, ridge_pca_file) \\\n",
    "                                        .add_pvolumes({out_path: preprocess_pca_container.pvolume})\n",
    "    \n",
    "    train_lasso_pca_container = train_pca_lasso_op(out_path, lasso_pca_file) \\\n",
    "                                        .add_pvolumes({out_path: preprocess_pca_container.pvolume})\n",
    "    \n",
    "    train_xgb_pca_container = train_pca_xgb_op(out_path, xgb_pca_file) \\\n",
    "                                        .add_pvolumes({out_path: preprocess_pca_container.pvolume})\n",
    "    \n",
    "    predict_ridge_pca_container = predict_pca_ridge_op(out_path, ridge_pca_file) \\\n",
    "                                        .add_pvolumes({out_path: train_ridge_pca_container.pvolume})\n",
    "    \n",
    "    predict_lasso_pca_container = predict_pca_lasso_op(out_path, lasso_pca_file) \\\n",
    "                                        .add_pvolumes({out_path: train_lasso_pca_container.pvolume})\n",
    "    \n",
    "    predict_xgb_pca_container = predict_pca_xgb_op(out_path, xgb_pca_file) \\\n",
    "                                        .add_pvolumes({out_path: train_xgb_pca_container.pvolume})\n",
    "    \n",
    "    \n",
    "    ridge_corr_result_container = dsl.ContainerOp(\n",
    "        name=\"predictions\",\n",
    "        image=\"library/bash:4.4.23\",\n",
    "        pvolumes={out_path: predict_ridge_corr_container.pvolume},\n",
    "        arguments=['head', f'{out_path}/ridge-corr.txt']\n",
    "    )\n",
    "    \n",
    "    \n",
    "    lasso_corr_result_container = dsl.ContainerOp(\n",
    "        name=\"predictions\",\n",
    "        image=\"library/bash:4.4.23\",\n",
    "        pvolumes={out_path: predict_lasso_corr_container.pvolume},\n",
    "        arguments=['head', f'{out_path}/lasso-corr.txt']\n",
    "    )\n",
    "    \n",
    "    \n",
    "    xgb_corr_result_container = dsl.ContainerOp(\n",
    "        name=\"predictions\",\n",
    "        image=\"library/bash:4.4.23\",\n",
    "        pvolumes={out_path: predict_xgb_corr_container.pvolume},\n",
    "        arguments=['head', f'{out_path}/xgb-corr.txt']\n",
    "    )\n",
    "    \n",
    "    ridge_pca_result_container = dsl.ContainerOp(\n",
    "        name=\"predictions\",\n",
    "        image=\"library/bash:4.4.23\",\n",
    "        pvolumes={out_path: predict_ridge_pca_container.pvolume},\n",
    "        arguments=['head', f'{out_path}/ridge-pca.txt']\n",
    "    )\n",
    "    \n",
    "    \n",
    "    lasso_pca_result_container = dsl.ContainerOp(\n",
    "        name=\"predictions\",\n",
    "        image=\"library/bash:4.4.23\",\n",
    "        pvolumes={out_path: predict_lasso_pca_container.pvolume},\n",
    "        arguments=['head', f'{out_path}/lasso-pca.txt']\n",
    "    )\n",
    "    \n",
    "    \n",
    "    xgb_pca_result_container = dsl.ContainerOp(\n",
    "        name=\"predictions\",\n",
    "        image=\"library/bash:4.4.23\",\n",
    "        pvolumes={out_path: predict_xgb_pca_container.pvolume},\n",
    "        arguments=['head', f'{out_path}/xgb-pca.txt']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_PATH = '/mnt'\n",
    "\n",
    "DOWNLOAD_URL = \"\"\n",
    "\n",
    "RIDGE_CORR_MODEL_PATH = 'ridge-corr-model.pkl'\n",
    "LASSO_CORR_MODEL_PATH = 'lasso-corr-model.pkl'\n",
    "XGB_CORR_MODEL_PATH = 'xgb-corr-model.pkl'\n",
    "\n",
    "RIDGE_PCA_MODEL_PATH = 'ridge-pca-model.pkl'\n",
    "LASSO_PCA_MODEL_PATH = 'lasso-pca-model.pkl'\n",
    "XGB_PCA_MODEL_PATH = 'xgb-pca-model.pkl'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_func = revenue_prediction_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'kubeflow_revenue_prediction'\n",
    "run_name = f'{pipeline_func.__name__} run'\n",
    "arguments = {\n",
    "    \"out_path\": OUT_PATH,\n",
    "    \"ridge_corr_file\": RIDGE_CORR_MODEL_PATH,\n",
    "    \"lasso_corr_file\": LASSO_CORR_MODEL_PATH,\n",
    "    \"xgb_corr_file\": XGB_CORR_MODEL_PATH,\n",
    "    \"ridge_pca_file\": RIDGE_PCA_MODEL_PATH,\n",
    "    \"lasso_pca_file\": LASSO_PCA_MODEL_PATH,\n",
    "    \"xgb_pca_file\": XGB_PCA_MODEL_PATH,\n",
    "    \"download_url\": DOWNLOAD_URL\n",
    "}\n",
    "\n",
    "kfp.compiler.Compiler().compile(pipeline_func, f'{experiment_name}.zip')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = kfp.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"/pipeline/#/experiments/details/2aef7eb4-59d4-412e-82ed-b44dc66324b8\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"/pipeline/#/runs/details/4e2c7c0f-71b1-48b7-aec3-4cb7a36fcec1\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_result = client.create_run_from_pipeline_func(pipeline_func,\n",
    "                                                 experiment_name=experiment_name,\n",
    "                                                 run_name=run_name,\n",
    "                                                 arguments=arguments\n",
    "                                                 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
